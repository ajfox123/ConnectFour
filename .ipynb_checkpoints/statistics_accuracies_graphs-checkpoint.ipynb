{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import Levenshtein as L\n",
    "import catch22\n",
    "import os\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "#reading in data from Spiker Box\n",
    "file1 = pd.read_csv('Spikerbox/Week_8/LRflutterx4_h2.txt', sep = ' ', header=None) \n",
    "file2 = pd.read_csv('Spikerbox/Week_10/LRflutter_a2.txt', sep = ' ', header=None) \n",
    "file3 = pd.read_csv('Spikerbox/Week_10/LRflutter_h1.txt', sep = ' ', header=None) \n",
    "file4 = pd.read_csv('Spikerbox/Week_10/LRflutter_s4.txt', sep = ' ', header=None) \n",
    "file5 = pd.read_csv('Spikerbox/Week_10/LRflutter_s5.txt', sep = ' ', header=None) \n",
    "file6 = pd.read_csv('Spikerbox/Week_10/LRflutter_s6.txt', sep = ' ', header=None) \n",
    "file7 = pd.read_csv('Spikerbox/Week_12/LLRRflfl_h1.txt') \n",
    "file8 = pd.read_csv('Spikerbox/Week_12/LLRRflfl_h3_charging.txt') \n",
    "file9 = pd.read_csv('Spikerbox/Week_12/LLRRflfl_n1.txt') \n",
    "file10 = pd.read_csv('Spikerbox/Week_12/LLRRflfl_s1.txt') \n",
    "\n",
    "\n",
    "x = 200 #number of points we average over\n",
    "\n",
    "# Filtering the data \n",
    "data1 = file1.iloc[:,1]\n",
    "data1 = data1.to_numpy()\n",
    "data1 = np.flip(data1)\n",
    "a1 = []\n",
    "i = 0\n",
    "while i <len(data1):     \n",
    "    a1.append(np.mean(data1[i:i+x]))\n",
    "    i += x\n",
    "\n",
    "data2 = file2.iloc[:,0]\n",
    "data2 = data2.to_numpy()\n",
    "data2 = np.flip(data2)\n",
    "a2 = []\n",
    "i = 0\n",
    "while i <len(data2):     \n",
    "    a2.append(np.mean(data2[i:i+x]))\n",
    "    i += x\n",
    "\n",
    "data3 = file3.iloc[:,0]\n",
    "data3 = data3.to_numpy()\n",
    "data3 = np.flip(data3)\n",
    "a3 = []\n",
    "i = 0\n",
    "while i <len(data3):     \n",
    "    a3.append(np.mean(data3[i:i+x]))\n",
    "    i += x\n",
    "\n",
    "data4 = file4.iloc[:,0] \n",
    "data4 = data4.to_numpy()\n",
    "data4 = np.flip(data4)\n",
    "a4 = []\n",
    "i = 0\n",
    "while i <len(data4):     \n",
    "    a4.append(np.mean(data4[i:i+x]))\n",
    "    i += x\n",
    "\n",
    "data5 = file5.iloc[:,0] \n",
    "data5 = data5.to_numpy()\n",
    "data5 = np.flip(data5)\n",
    "a5 = []\n",
    "i = 0\n",
    "while i <len(data5):     \n",
    "    a5.append(np.mean(data5[i:i+x]))\n",
    "    i += x\n",
    "\n",
    "data6 = file6.iloc[:,0]\n",
    "data6 = data6.to_numpy()\n",
    "data6 = np.flip(data6)\n",
    "a6 = []\n",
    "i = 0\n",
    "while i <len(data6):     \n",
    "    a6.append(np.mean(data6[i:i+x]))\n",
    "    i += x\n",
    "a6 = a6[1100:]\n",
    "\n",
    "data7 = file7.iloc[:,0]\n",
    "data7 = data7.to_numpy()\n",
    "data7 = np.flip(data7)\n",
    "a7 = []\n",
    "i = 0\n",
    "while i <len(data7):     \n",
    "    a7.append(np.mean(data7[i:i+x]))\n",
    "    i += x\n",
    "a7 = a7[350:]\n",
    "\n",
    "data8 = file8.iloc[:,0]\n",
    "data8 = data8.to_numpy()\n",
    "data8 = np.flip(data8)\n",
    "a8 = []\n",
    "i = 0\n",
    "while i <len(data8):     \n",
    "    a8.append(np.mean(data8[i:i+x]))\n",
    "    i += x\n",
    "a8 = a8[1500:]\n",
    "\n",
    "data9 = file9.iloc[:,0]\n",
    "data9 = data9.to_numpy()\n",
    "data9 = np.flip(data9)\n",
    "a9 = []\n",
    "i = 0\n",
    "while i <len(data9):     \n",
    "    a9.append(np.mean(data9[i:i+x]))\n",
    "    i += x\n",
    "a9 = a9[900:]\n",
    "\n",
    "data10 = file10.iloc[:,0]\n",
    "data10 = data10.to_numpy()\n",
    "data10 = np.flip(data10)\n",
    "a10 = []\n",
    "i = 0\n",
    "while i <len(data10):     \n",
    "    a10.append(np.mean(data10[i:i+x]))\n",
    "    i += x\n",
    "a10 = a10[250:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations of statistics for the file a1\n",
    "\n",
    "time2 = np.arange(0, 60, 0.02)\n",
    "sd = [] # Initialise standard deviation list\n",
    "dif = [] # Initialise range list \n",
    "peaks1 = [] # Initialise peaks list \n",
    "x = 0\n",
    "time = []\n",
    "last_seq = np.empty(0)\n",
    "l = len(a1) # Length of file \n",
    "b = 0\n",
    "while b < l:\n",
    "    # Take one second of data\n",
    "    if l-b < 50:\n",
    "        data_temp = a1[b:(l-1)]\n",
    "    else:\n",
    "        data_temp = a1[b:(b+50)]\n",
    "    combined = np.concatenate((last_seq, data_temp), axis = None)\n",
    "\n",
    "    c = 0\n",
    "    if len(combined) > 0:\n",
    "        movement = len(combined) - 50 # How much the rolling window can move before reaching end of 2 second sequence\n",
    "        while movement - c > 0: # Rolling window through the combined 2 seconds of data \n",
    "            interval = combined[c:(c+50)] # Current window being evaluated\n",
    "            sd.append(np.std(interval)) # Standard deviation\n",
    "            dif.append(np.max(interval) - np.min(interval)) # Range\n",
    "            peaks1.append(len(scipy.signal.find_peaks(interval, prominence=10)[0])) # Number of peaks \n",
    "            time.append(x) \n",
    "            x += 0.1\n",
    "            c += 5 # Moving window by 0.1 seconds \n",
    "    last_seq = data_temp # Storing last second of data \n",
    "    b += 50 # Look at next 1 second of data\n",
    "\n",
    "# Plotting statistics \n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15, 8))\n",
    "fig.suptitle('Statistics for Left, Right and Flutter sequence repeated four times', fontsize=22)\n",
    "axes[0][0].plot(time2, a1)\n",
    "axes[0][0].set_title('Input Signal', fontsize=15)\n",
    "axes[0][0].set_xlabel(\"\")\n",
    "axes[0][0].set_ylabel('\\u03C3', fontsize=15)\n",
    "axes[0][1].plot(time, sd)\n",
    "axes[0][1].set_title('Standard Deviation', fontsize=15)\n",
    "axes[0][1].set(xlabel=\"\", ylabel='Range')\n",
    "axes[1][0].plot(time, dif)\n",
    "axes[1][0].set_title('Range', fontsize=15)\n",
    "axes[1][0].set(xlabel=\"Time (seconds)\", ylabel='Crossings')\n",
    "axes[1][1].plot(time, peaks1)\n",
    "axes[1][1].set_title('Peaks with a prominence of at least 10', fontsize=15)\n",
    "axes[1][1].set(xlabel=\"Time (seconds)\", ylabel='Peaks')\n",
    "plt.show()\n",
    "#fig.savefig('statistics.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules Based eye movement detection\n",
    "def Detection(seq, std_thresh, diff_thresh, prom_threshold, peaks_thresh):\n",
    "    # Statistics for sequence\n",
    "    std = np.std(seq) # Standard Deviation\n",
    "    diff = np.max(seq) - np.min(seq)\n",
    "    peaks = len(scipy.signal.find_peaks(seq, prominence=prom_threshold)[0])\n",
    "    maxval = np.argmax(seq)\n",
    "    minval = np.argmin(seq)\n",
    "    if peaks > peaks_thresh:\n",
    "        return 'F'\n",
    "    elif std > std_thresh and diff > diff_thresh:\n",
    "        if maxval > minval:\n",
    "            return 'L'\n",
    "        else:\n",
    "            return 'R'\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "# Files and their correct sequences of eye movements to be used for the evaluation\n",
    "files = [[a1, 'LRFLRFLRF'], [a2, 'RLFRLFRLF'], [a7, 'LLRRFFLLRRFFLLRRFFLLR'], [a8, 'LLRRFFLLRRFF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left eye movements for KNN model \n",
    "L1 = a3[345:440]\n",
    "L2 = a3[1395:1495]\n",
    "L3 = a4[390:488]\n",
    "L4 = a4[1302:1397]\n",
    "L5 = a5[1195:1295]\n",
    "L6 = a5[295:375]\n",
    "L7 = a6[145:235]\n",
    "L8 = a9[840:890]\n",
    "L9 = a9[950:1000]\n",
    "L10 = a10[1115:1165]\n",
    "L11 = a10[1205:1255]\n",
    "\n",
    "# Right eye movements for KNN model\n",
    "R1 = a3[655:755]\n",
    "R2 = a3[1665:1755]\n",
    "R3 = a4[647:743]\n",
    "R4 = a4[1555:1655]\n",
    "R5 = a5[545:655]\n",
    "R6 = a5[1447:1540]\n",
    "R7 = a6[400:500]\n",
    "R8 = a9[590:640]\n",
    "R9 = a9[770:810]\n",
    "R10 = a10[840:890]\n",
    "R11 = a10[930:980]\n",
    "\n",
    "# Flutter eye movments for KNN model\n",
    "F1 = a3[1900:1970]\n",
    "F2 = a3[2750:2810]\n",
    "F3 = a4[950:1020]\n",
    "F4 = a4[2750:2800]\n",
    "F5 = a5[900:1000]\n",
    "F6 = a5[1760:1810]\n",
    "F7 = a6[700:770]\n",
    "F8 = a9[1075:1125]\n",
    "F9 = a9[1205:1255]\n",
    "F10 = a10[1350:1400]\n",
    "F11 = a10[1550:1600]\n",
    "\n",
    "# Extracting the catch22 features for the training data\n",
    "m1L1 = catch22.catch22_all(L1)['values']\n",
    "m1L2 = catch22.catch22_all(L2)['values']\n",
    "m1L3 = catch22.catch22_all(L3)['values']\n",
    "m1L4 = catch22.catch22_all(L4)['values']\n",
    "m1L5 = catch22.catch22_all(L5)['values']\n",
    "m1L6 = catch22.catch22_all(L6)['values']\n",
    "m1L7 = catch22.catch22_all(L7)['values']\n",
    "m1L8 = catch22.catch22_all(L8)['values']\n",
    "m1L9 = catch22.catch22_all(L9)['values']\n",
    "m1L10 = catch22.catch22_all(L10)['values']\n",
    "m1L11 = catch22.catch22_all(L11)['values']\n",
    "m1R1 = catch22.catch22_all(R1)['values']\n",
    "m1R2 = catch22.catch22_all(R2)['values']\n",
    "m1R3 = catch22.catch22_all(R3)['values']\n",
    "m1R4 = catch22.catch22_all(R4)['values']\n",
    "m1R5 = catch22.catch22_all(R5)['values']\n",
    "m1R6 = catch22.catch22_all(R6)['values']\n",
    "m1R7 = catch22.catch22_all(R7)['values']\n",
    "m1R8 = catch22.catch22_all(R8)['values']\n",
    "m1R9 = catch22.catch22_all(R9)['values']\n",
    "m1R10 = catch22.catch22_all(R10)['values']\n",
    "m1R11 = catch22.catch22_all(R11)['values']\n",
    "m1F1 = catch22.catch22_all(F1)['values']\n",
    "m1F2 = catch22.catch22_all(F2)['values']\n",
    "m1F3 = catch22.catch22_all(F3)['values']\n",
    "m1F4 = catch22.catch22_all(F4)['values']\n",
    "m1F5 = catch22.catch22_all(F5)['values']\n",
    "m1F6 = catch22.catch22_all(F6)['values']\n",
    "m1F7 = catch22.catch22_all(F7)['values']\n",
    "m1F8 = catch22.catch22_all(F8)['values']\n",
    "m1F9 = catch22.catch22_all(F9)['values']\n",
    "m1F10 = catch22.catch22_all(F10)['values']\n",
    "m1F11 = catch22.catch22_all(F11)['values']\n",
    "\n",
    "# KNN model to predict Left, Right and Flutter eye movements\n",
    "X = np.array([m1L1, m1L2, m1L3, m1L4, m1L5, m1L6, m1L7, m1L8, m1L9, m1L10, m1L11, m1R1, m1R2, m1R3, m1R4, m1R5, m1R6, m1R7, m1R8, m1R9, m1R10, m1R11, m1F1, m1F2, m1F3, m1F4, m1F5, m1F6, m1F7, m1F8, m1F9, m1F10, m1F11])\n",
    "y = np.array(['L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F'])\n",
    "\n",
    "# Scaling the data so that the features have an equal weight in the model\n",
    "X_scaled = X\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_scaled)\n",
    "X_scaled = scaler.transform(X_scaled)\n",
    "\n",
    "# Testing the accuracy \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred) # Predicted sequence\n",
    "print(y_test) # Actual sequence\n",
    "\n",
    "# Final KNN model to be used in the classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "\n",
    "# KNN model to predict Left and Right eye movements\n",
    "X2 = np.array([m1L1, m1L2, m1L3, m1L4, m1L5, m1L6, m1L7, m1L8, m1L9, m1L10, m1L11, m1R1, m1R2, m1R3, m1R4, m1R5, m1R6, m1R7, m1R8, m1R9, m1R10, m1R11])\n",
    "y2 = np.array(['L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R'])\n",
    "\n",
    "# Scaling the data so that the features have an equal weight in the model\n",
    "X2_scaled = X2\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X2_scaled)\n",
    "X2_scaled = scaler.transform(X2_scaled)\n",
    "\n",
    "# Testing the accuracy\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_scaled, y2, test_size=0.3)\n",
    "classifier2 = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier2.fit(X2_train, y2_train)\n",
    "y2_pred = classifier2.predict(X2_test)\n",
    "print(y2_pred) # Pedicated sequence\n",
    "print(y2_test) # Actual sequence\n",
    "\n",
    "# Final KNN model to be used in the classifier \n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model2.fit(X2_scaled, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Window lengths used for the rolling window\n",
    "window_lengths = [0.6, 0.8, 1, 1.2, 1.4, 1.6] \n",
    "\n",
    "# Initialise lists which contain accuracy for each window length\n",
    "final_accuracy1 = []\n",
    "final_accuracy2 = []\n",
    "\n",
    "# Compute accuracies for Rule Based Classifier and Combined KNN and Rule Based classifier\n",
    "for window_length in window_lengths: # Looping through each window length \n",
    "    window_size = int(window_length * 50)\n",
    "    tot_dist = 0 # Total Levenshtein Distance to be used for accuracy calculation\n",
    "    num_movements = 0 # Number of movements to be used for accuracy calculation\n",
    "    tot_dist2 = 0\n",
    "    num_movements2 = 0\n",
    "    if window_size < 1: # Smaller window sizes don't capture as many peaks so they need a smaller peak threshold\n",
    "        peak_thresh = 1\n",
    "    else:\n",
    "        peak_thresh = 2 \n",
    "\n",
    "    for file in files: #Looping through each file\n",
    "        l = len(file[0]) # Length of file\n",
    "        data = file[0]\n",
    "        b = 0 # Variable that indicates what part we are looking at in the file\n",
    "        calibrating = True\n",
    "        start = True\n",
    "        last_seq = np.empty(0) # Initialse array to store the previous second of data\n",
    "        count = 0 # Number of intervals inbetween eye movements (used to distinguish between eye movements)\n",
    "        ccount = 0 # Same as count but for calibration stage \n",
    "        best_diff = 0 # Storing the largest range during an eye movement for classification purposes\n",
    "        cbest_diff = 0 # Same as best_diff but for calibration stage\n",
    "        cstds = np.empty(0) # Initialse array to standard deviations from calibration stage\n",
    "        cdiffs = np.empty(0) # Initialse array to ranges from calibration stage\n",
    "        final = [] # Accuracies for each file\n",
    "        final2 = []\n",
    "\n",
    "        while b < l: \n",
    "            # Collecting 1 second of data\n",
    "            if l-b < window_size:\n",
    "                data_temp = data[b:(b-1)]\n",
    "            else:\n",
    "                data_temp = data[b:(b+window_size)]\n",
    "\n",
    "            data_temp = np.array(data_temp)\n",
    "            # Combining the previous and current second of data to loop through\n",
    "            combined = np.concatenate((last_seq, data_temp), axis = None) \n",
    "            \n",
    "            # Calibration Stage\n",
    "            if calibrating and b > 0: # b > 0 makes sure we don't look at first second of data as it tends to be messy\n",
    "                if start:\n",
    "                    arrs = np.split(data_temp, 5)\n",
    "                    base_std = np.std(data_temp)\n",
    "                    if base_std > 5:\n",
    "                        base_std = 5\n",
    "                    start = False\n",
    "                else:\n",
    "                    c = 0\n",
    "                    movement = len(combined) - window_size # How much the rolling window can move before reaching end of 2 second sequence\n",
    "                    while movement - c > 0: # Rolling window through the combined 2 seconds of data\n",
    "                        interval = combined[c:(c+window_size)] # Current interval being evaluated \n",
    "                        \n",
    "                        # Statistics for interval \n",
    "                        cstd = np.std(interval) # Standard Deviation\n",
    "                        cdiff = np.max(interval) - np.min(interval) # Range\n",
    "                        cpeaks = len(scipy.signal.find_peaks(interval, prominence=10)[0]) # Peaks\n",
    "                        \n",
    "                        if cpeaks > peak_thresh: # Signals the end of the calibration stage \n",
    "                            calibrating = False\n",
    "                            cpeaks = 0\n",
    "                            cstds = np.flip(np.sort(cstds)) # Rank standard deviations for each eye movement\n",
    "                            cdiffs = np.flip(np.sort(cdiffs)) # Range each range for the eye movements\n",
    "                            \n",
    "                            # Determining the standard deviation threshold \n",
    "                            max_std = cstds[0]\n",
    "                            if len(cstds) > 3:\n",
    "                                low_std = cstds[2]\n",
    "                            elif len(cstds) == 1:\n",
    "                                low_std = max_std\n",
    "                            else:\n",
    "                                low_std = cstds[1]\n",
    "                            std_threshold = low_std/2 # Standard deviation threshold\n",
    "                            \n",
    "                            # Determining the range threshold\n",
    "                            max_diff = cdiffs[0]\n",
    "                            if len(cdiffs) > 3:\n",
    "                                low_diff = cdiffs[2]\n",
    "                            elif len(cdiffs) == 1:\n",
    "                                low_diff = max_diff\n",
    "                            else:\n",
    "                                low_diff = cdiffs[1]\n",
    "                            diff_threshold = low_diff/2 # Range threshold\n",
    "\n",
    "                            prom_threshold = 10\n",
    "                            break  # Leave calibration stage\n",
    "\n",
    "                        elif cstd > 2*base_std and ccount > 4:\n",
    "                            # Finding the interval from an eye movement which contains the largest range\n",
    "                            if cdiff >= cbest_diff:\n",
    "                                cbest_diff = cdiff\n",
    "                                cbest = interval\n",
    "                            elif (cbest_diff - cdiff) > 10:\n",
    "                                cstds = np.append(cstds, np.std(cbest)) \n",
    "                                cdiffs = np.append(cdiffs, cbest_diff)\n",
    "                                cbest = 0\n",
    "                                cbest_diff = 0\n",
    "                                ccount = 0\n",
    "                        else:\n",
    "                            ccount += 1\n",
    "\n",
    "                        c += 5 # Moving the window 0.1 seconds \n",
    "\n",
    "            elif b > 0:\n",
    "                d = 0\n",
    "                if len(combined) > window_size:\n",
    "                    movement = len(combined) - window_size # How much the rolling window can move before reaching end of 2 second sequence\n",
    "                    while movement - d > 0: # Rolling window through the combined 2 seconds of data\n",
    "                        interval = combined[d:(d+window_size)] # Current interval being evaluated \n",
    "                        predicted = Detection(interval, std_threshold, diff_threshold, prom_threshold, peak_thresh) # Predicted eye movement from Rules-Based Classifier\n",
    "                        ran = np.max(interval) - np.min(interval) # Range \n",
    "                        sdi = np.std(interval) # Standard Devaition \n",
    "                        \n",
    "                        # Counting number of NA's inbetween eye movements to separate them \n",
    "                        if predicted == 'NA':\n",
    "                            count += 1\n",
    "                            \n",
    "                        # Flutter detected\n",
    "                        elif predicted == 'F' and count >= 5:\n",
    "                            count = 0\n",
    "                            best = 0\n",
    "                            best_diff = 0\n",
    "                            final.append(predicted)\n",
    "                            final2.append(predicted)\n",
    "                        \n",
    "                        # Detection of an eye movement occurring due to significant standard deviation and range\n",
    "                        elif (sdi > std_threshold or ran > diff_threshold) and count >= 5:\n",
    "                            # Finding the interval from an eye movement which contains the largest range\n",
    "                            if ran >= best_diff:\n",
    "                                best_diff = ran\n",
    "                                best = interval # Store interval with largest range\n",
    "                            elif (best_diff - ran) > 10:\n",
    "                                actual = Detection(best, std_threshold, diff_threshold, prom_threshold, peak_thresh)\n",
    "                                final.append(actual) # Final detection used for accuracy\n",
    "                                \n",
    "                                # KNN eye movement prediction\n",
    "                                interval_features2 = catch22.catch22_all(best)['values'] # catch22 features from interval\n",
    "                                full2 = np.vstack((X2, [interval_features2]))\n",
    "                                # Scaling variables\n",
    "                                scaler = MinMaxScaler()\n",
    "                                scaler.fit(full2)\n",
    "                                full2 = scaler.transform(full2)\n",
    "                                actual2 = model2.predict([full2[-1]])[0] # Predicted eye movement \n",
    "                                \n",
    "                                final2.append(actual2) # Final detection used for accuracy \n",
    "                                \n",
    "                                best = 0\n",
    "                                best_diff = 0\n",
    "                                count = 0\n",
    "                        d += 5 # Moving the window 0.1 seconds \n",
    "            last_seq = data_temp\n",
    "            b += window_size\n",
    "        result = ''.join(final) # Final sequence of eye movments for Rules Based classifier \n",
    "        accuracy = L.distance(result, file[1]) # Levenshtein Distance\n",
    "        num_movements += len(file[1])\n",
    "        tot_dist += accuracy\n",
    "        \n",
    "        result2 = ''.join(final2) # Final sequence of eye movements for combined KNN and Rules Based classifier \n",
    "        accuracy2 = L.distance(result2, file[1]) # Levenshtein Distance\n",
    "        num_movements2 += len(file[1])\n",
    "        tot_dist2 += accuracy2\n",
    "        \n",
    "    final_accuracy1.append(1-tot_dist/num_movements) # Append final accuracy for current window size\n",
    "    final_accuracy2.append(1-tot_dist2/num_movements2) # Append final accuracy for current window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialise list to contain accuracies for each window length \n",
    "final_accuracy3 = []\n",
    "\n",
    "# Combpute accuracy for KNN Classifier\n",
    "for window_length in window_lengths: # Looping through each window length \n",
    "    window_size = int(window_length * 50)\n",
    "    tot_dist = 0 # Total Levenshtein Distance to be used for accuracy calculation\n",
    "    num_movements = 0 # Number of movements to be used for accuracy calculation\n",
    "    if window_size < 1: # Smaller window sizes don't capture as many peaks so they need a smaller peak threshold\n",
    "        peak_thresh = 1\n",
    "    else:\n",
    "        peak_thresh = 2\n",
    "\n",
    "    for file in files:\n",
    "        l = len(file[0]) # Length of file\n",
    "        data = file[0]\n",
    "        b = 0 # Variable that indicates what part we are looking at in the file\n",
    "        calibrating = True\n",
    "        start = True\n",
    "        last_seq = np.empty(0) # Initialise array to store previoous second of data\n",
    "        count = 0 # Number of intervals between eye movements\n",
    "        ccount = 0 # Same as count but for calibration stage\n",
    "        count2 = 0\n",
    "        best_diff = 0 # Storing the largest range during an eye movement for classification purposes\n",
    "        cbest_diff = 0 # Same as best_diff but for calibration stage\n",
    "        cstds = np.empty(0) # Initialse array to standard deviations from calibration stage\n",
    "        cdiffs = np.empty(0) # Initialse array to ranges from calibration stage\n",
    "        final = [] # Accuracies for ach file\n",
    "\n",
    "        while b < l:\n",
    "            # Collecting 1 second of data\n",
    "            if l-b < window_size:\n",
    "                data_temp = data[b:(b-1)]\n",
    "            else:\n",
    "                data_temp = data[b:(b+window_size)]\n",
    "\n",
    "            data_temp = np.array(data_temp)\n",
    "            # Combining the previous and current second of data to loop through\n",
    "            combined = np.concatenate((last_seq, data_temp), axis = None)\n",
    "            # Calibration stage \n",
    "            if calibrating and b > 0:\n",
    "                if start: \n",
    "                    arrs = np.split(data_temp, 5)\n",
    "                    base_std = np.std(data_temp)\n",
    "                    if base_std > 5:\n",
    "                        base_std = 5\n",
    "                    start = False\n",
    "                else:\n",
    "                    c = 0\n",
    "                    movement = len(combined) - window_size # How much the rolling window can move before reaching end of 2 second sequence\n",
    "                    while movement - c > 0: # Rolling window through the combined 2 seconds of data \n",
    "                        interval = combined[c:(c+window_size)] # Current interval being evaluated\n",
    "                        \n",
    "                        # Statistics for interval\n",
    "                        cstd = np.std(interval) # Standard Deviation\n",
    "                        cdiff = np.max(interval) - np.min(interval) # Range\n",
    "                        cpeaks = len(scipy.signal.find_peaks(interval, prominence=10)[0]) # Peaks\n",
    "                        \n",
    "                        if cpeaks > peak_thresh: # Signals the end of the calibration stage\n",
    "                            calibrating = False\n",
    "                            cpeaks = 0\n",
    "                            cstds = np.flip(np.sort(cstds)) # Range standard deviations for eye movements\n",
    "                            cdiffs = np.flip(np.sort(cdiffs)) # Rank the ranges for eye movements\n",
    "                            \n",
    "                            # Determining the standard devaition threshold\n",
    "                            max_std = cstds[0]\n",
    "                            if len(cstds) > 3:\n",
    "                                low_std = cstds[2]\n",
    "                            elif len(cstds) == 1:\n",
    "                                low_std = max_std\n",
    "                            else:\n",
    "                                low_std = cstds[1]\n",
    "                            std_threshold = low_std/1.5 # Standard Deviation threshold\n",
    "                            \n",
    "                            # Determining the range threshold \n",
    "                            max_diff = cdiffs[0]\n",
    "                            if len(cdiffs) > 3:\n",
    "                                low_diff = cdiffs[2]\n",
    "                            elif len(cdiffs) == 1:\n",
    "                                low_diff = max_diff\n",
    "                            else:\n",
    "                                low_diff = cdiffs[1]\n",
    "                            diff_threshold = low_diff/1.5 # Range threshold \n",
    "\n",
    "                            prom_threshold = 10\n",
    "                            break # Leave calibration stage \n",
    "\n",
    "                        elif cstd > 2*base_std and ccount > 4:\n",
    "                            # Finding the interval from an eye movement which contains the largest range\n",
    "                            if cdiff >= cbest_diff:\n",
    "                                cbest_diff = cdiff\n",
    "                                cbest = interval\n",
    "                            elif (cbest_diff - cdiff) > 10:\n",
    "                                cstds = np.append(cstds, np.std(cbest)) \n",
    "                                cdiffs = np.append(cdiffs, cbest_diff)\n",
    "                                cbest = 0\n",
    "                                cbest_diff = 0\n",
    "                                ccount = 0\n",
    "                        else:\n",
    "                            ccount += 1\n",
    "\n",
    "                        c += 5\n",
    "                    \n",
    "            # After calibration stage is finished \n",
    "            elif b > 0:\n",
    "                d = 0 \n",
    "                if len(combined) > window_size:\n",
    "                    movement = len(combined) - window_size # How much the rolling window can move before reaching end of 2 second sequence\n",
    "                    while movement - d > 0: # Rolling window through the combined 2 seconds of data\n",
    "                        interval = combined[d:(d+window_size)]\n",
    "                        ran = np.max(interval) - np.min(interval) # Range\n",
    "                        sdi = np.std(interval) # Standard devation\n",
    "                        \n",
    "                        # KNN eye movement prediction\n",
    "                        interval_features = catch22.catch22_all(interval)['values'] # catch22 features\n",
    "                        full = np.vstack((X, [interval_features]))\n",
    "                        # Scaling variables\n",
    "                        scaler = MinMaxScaler()\n",
    "                        scaler.fit(full)\n",
    "                        full = scaler.transform(full)\n",
    "                        actual = model.predict([full[-1]])[0] # Predicted eye movement\n",
    "                        \n",
    "                        # Detection of an eye movement occurring due to significant standard deeviation and range \n",
    "                        if (sdi > std_threshold or ran > diff_threshold) and count >= 10:\n",
    "                            count2 += 1\n",
    "                            if count2 >= 12: # Gets a prediction from roughly the middle of an eye movement \n",
    "                                final.append(actual) # Final detection used for accuracy\n",
    "                                best = 0\n",
    "                                best_diff = 0\n",
    "                                count = 0\n",
    "                                count2 = 0\n",
    "                        \n",
    "                        else: # counting number of times when no eye movements are occurring inbetween eye movements\n",
    "                            count += 1\n",
    "                            \n",
    "                        d += 5 # Moving the window by 0.1 seconds \n",
    "            last_seq = data_temp # Recording the last second of data \n",
    "            b += window_size\n",
    "        result = ''.join(final) # Final sequence of eye movements for KNN classifier\n",
    "        accuracy = L.distance(result, file[1]) # Levenshtein distance    \n",
    "        num_movements += len(file[1])\n",
    "        tot_dist += accuracy\n",
    "\n",
    "    final_accuracy3.append(1-tot_dist/num_movements) # Append final accuracy for current window size\n",
    "\n",
    "print(final_accuracy1)\n",
    "print(final_accuracy3)\n",
    "print(final_accuracy2)\n",
    "print()\n",
    "\n",
    "# Plotting the different accuries for different classifiers and window lengths \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(window_lengths,final_accuracy1, label='Rules-Based Classifier')\n",
    "plt.plot(window_lengths,final_accuracy3, label='KNN w/ catch22 features')\n",
    "plt.plot(window_lengths,final_accuracy2, label='Combined KNN and Rules-Based Classifier')\n",
    "plt.title(\"Accuracy for Different Classifiers and Window Lengths\", fontsize=17)\n",
    "plt.xlabel(\"Window length (seconds)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
